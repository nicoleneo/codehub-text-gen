{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "sanitised_lines = []\n",
    "with open('tweets.txt') as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        line = bytes(line, 'utf-8').decode('utf-8', 'ignore')\n",
    "        line = re.sub(r'''(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:'\".,<>?«»“”‘’]))''', \" \", line)\n",
    "        line = line.replace(\"\\\"\", \"\")\n",
    "        line = line.rstrip()\n",
    "        line = line.rstrip('_')\n",
    "        if line is not '':\n",
    "            sanitised_lines.append(line+'\\n')\n",
    "#print(sanitised_lines)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('sanitised_tweets.txt', 'w+') as san:\n",
    "    san.writelines(sanitised_lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Trump quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pickle, argparse, time, random, sys\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from hmmlearn import hmm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "filename = \"trump/hmm.builtin.8\"\n",
    "num_lines = 1\n",
    "args_num_words = 12\n",
    "args_seed = datetime.now().microsecond\n",
    "\n",
    "def num_words(seed):\n",
    "    return args_num_words\n",
    "\n",
    "def generate_quote(num_words_sentence):\n",
    "    sentence = []\n",
    "    with open(\"{0}.le\".format(filename), \"rb\") as f:\n",
    "        le = pickle.load(f)\n",
    "    model = joblib.load(\"{0}.pkl\".format(filename))\n",
    "\n",
    "    seed = args_seed\n",
    "    for _i in range(num_lines):\n",
    "        random_len = num_words(seed=seed)\n",
    "        seed = seed + 1\n",
    "\n",
    "        symbols, _states = model.sample(random_len, random_state=seed)\n",
    "\n",
    "        output = le.inverse_transform(np.squeeze(symbols))\n",
    "        for word in output:\n",
    "            sentence.append(word)\n",
    "    sentence = \" \".join(sentence)\n",
    "    print(sentence)\n",
    "    return sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bernie &amp; ۢ just @brithume politics !!!#trump2016 one-sided big: had trump both\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'bernie &amp; ۢ just @brithume politics !!!#trump2016 one-sided big: had trump both'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_words_sentence = 12\n",
    "generate_quote(num_words_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
